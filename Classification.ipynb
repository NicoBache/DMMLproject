{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf035111",
   "metadata": {},
   "source": [
    "#  Notebook 02 - Classificazione binaria\n",
    "\n",
    "Classificazione del rischio di insolvenza con modelli di Machine Learning.\n",
    "\n",
    "Questo notebook utilizza il dataset pre-elaborato salvato in `application_train_cleaned.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9278b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”½ Caricamento dati pre-elaborati\n",
    "df = pd.read_csv(\"Dataset/application_train_cleaned.csv\")\n",
    "print(f\" Dataset caricato: {df.shape[0]} righe, {df.shape[1]} colonne\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a8d7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ Separazione tra features e target\n",
    "X = df.drop(\"TARGET\", axis=1)\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "# ðŸ”€ Train-test split con stratificazione\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"âœ… Split completato:\")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78e7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Carica il dataset preprocessato\n",
    "df = pd.read_csv(\"Dataset/application_train_cleaned.csv\")\n",
    "\n",
    "X = df.drop(\"TARGET\", axis=1)\n",
    "y = df[\"TARGET\"]\n",
    "\n",
    "pipelines = {\n",
    "    \"Random Forest\": Pipeline([\n",
    "        ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42, n_jobs=-1))\n",
    "    ]),\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
    "    ]),\n",
    "    \"LightGBM\": Pipeline([\n",
    "        ('classifier', LGBMClassifier(random_state=42))\n",
    "    ]),\n",
    "    \"XGBoost\": Pipeline([\n",
    "        ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss',\n",
    "                                    scale_pos_weight=(y == 0).sum() / (y == 1).sum(), n_jobs=-1))\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    print(f\"Valutazione: {name}\")\n",
    "    scores = cross_val_score(pipe, X, y, cv=skf, scoring='f1_macro', n_jobs=-1)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"F1 macro mean\": scores.mean(),\n",
    "        \"F1 macro std\": scores.std()\n",
    "    })\n",
    "    print(f\"{name}: F1 macro (CV) = {scores.mean():.3f} Â± {scores.std():.3f}\")\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "print(\"\\nCross-validation results:\")\n",
    "print(df_results.sort_values(\"F1 macro mean\", ascending=False))\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(df_results[\"Model\"], df_results[\"F1 macro mean\"],\n",
    "         yerr=df_results[\"F1 macro std\"], capsize=5, alpha=0.7, color='skyblue')\n",
    "plt.title(\"F1 macro (mean Â± std)\", fontsize=14)\n",
    "plt.ylabel(\"F1 macro\", fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(df_results[\"F1 macro mean\"], df_results[\"F1 macro std\"])):\n",
    "    plt.text(i, mean + std + 0.02, f'{mean:.3f}Â±{std:.3f}', \n",
    "         ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff0de5",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Considerazioni iniziali\n",
    "\n",
    "Abbiamo testato tre modelli base:\n",
    "- **Logistic Regression** con bilanciamento interno (`class_weight='balanced'`)\n",
    "- **Random Forest** robusto e non sensibile a feature scaling\n",
    "- **LightGBM** molto competitivo in letteratura\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
